---
title: "TD VI: Inteligencia Artificial - Trabajo práctico 1 (2024 2do semestre)"
author: "Luca Mazzarello y Camila Migdal"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#install.packages("rpart")
#install.packages("writexl")
#install.packages("dplyr")
#install.packages("ggplot2")
#install.packages("rpart.plot")
#install.packages("caret")
#install.packages("pROC")
#install.packages("plotly")
library(rpart)
library(writexl)
library(dplyr)
library(ggplot2)
library(rpart.plot)
library(caret)
library(pROC)
library(plotly)
library(reshape2)
library(scales)

```

## Objetivo

El objetivo de este trabajo práctico es que realicen un análisis completo utilizando árboles de decisión en R. El trabajo se presentará en formato R Markdown, integrando código, resultados y explicaciones en un único documento.

Hemos elegido R como lenguaje de programación para este TP por una razón fundamental: queremos que adquieran intuiciones sobre el impacto que tiene en la performance de los modelos el hecho de que el mismo árbol maneje los valores faltantes (NAs). Esta característica está implementada en R, específicamente en la librería **rpart**, pero no está disponible en las implementaciones populares de Python.

El trabajo práctico consiste en generar un archivo R Markdown (.Rmd) que incluya todo el código, análisi s yexplicaciones hechas por ustedes. A continuación, se detalla la estructura que debe tener este archivo.

# 1. Introducción al problema

El conjunto de datos contiene información sobre características demográficas y biométricas de individuos, con el objetivo de predecir si una persona consume alcohol o no. La variable objetivo es DRK_YN, que indica si la persona consume alcohol (Yes) o no (No). Esta fue descargada de [kaggle](https://www.kaggle.com/datasets/sooyoungher/smoking-drinking-dataset)

## Variables Principales:

-   **sex**: Género de la persona (Male/Female).
-   **age**: Edad de la persona.
-   **height**: Altura de la persona en centímetros.
-   **weight**: Peso de la persona en kilogramos.
-   **waistline**: Circunferencia de la cintura en centímetros.
-   **sight_left / sight_right**: Agudeza visual en el ojo izquierdo/derecho.
-   **hear_left / hear_right**: Capacidad auditiva en el oído izquierdo/derecho.
-   **SBP**: Presión arterial sistólica.
-   **LDL_chole**: Niveles de colesterol LDL.
-   **triglyceride**: Niveles de triglicéridos.
-   **hemoglobin**: Niveles de hemoglobina.
-   **urine_protein**: Presencia de proteínas en la orina.
-   **serum_creatinine**: Niveles de creatinina en suero.
-   **SGOT_AST / SGOT_ALT**: Enzimas hepáticas.
-   **gamma_GTP**: Enzima hepática relacionada con el consumo de alcohol.
-   **SMK_stat_type_cd**: Código de estado de fumador.
-   **DRK_YN**: Variable objetivo que indica si la persona consume alcohol o no (Yes/No).

## Problema a Resolver:

El objetivo es desarrollar un modelo predictivo que, basado en las características biométricas, determine si una persona es consumidora de alcohol o no.

## ¿Por qué esta elección?

Consideramos que este dataset es adecuado para el uso de árboles de decisión porque incluye tanto variables categóricas (como sex y SMK_stat_type_cd) como numéricas (como age, height, weight, entre otras), lo cual es ideal para este tipo de modelo. Además, la relación entre algunas variables biométricas y el consumo de alcohol puede no ser lineal, y los árboles de decisión son eficaces para manejar este tipo de relaciones complejas.

El dataset también cuenta con variables fuertemente relacionadas con el consumo de alcohol, como SGOT_AST, SGOT_ALT y gamma_GTP. Los árboles de decisión pueden identificar y priorizar las variables más importantes, ayudando a manejar la redundancia de manera eficiente.

Además, los árboles de decisión manejan de manera efectiva los datos faltantes y son robustos frente a outliers, lo que los hace especialmente flexibles y adecuados para la clasificación binaria, como en este caso, donde se busca predecir el consumo de alcohol. Finalmente, la capacidad de los árboles de decisión para visualizar y estructurar los datos facilita enormemente el análisis e interpretación del problema planteado.

# 2. Preparación de los datos

## Cargamos el conjunto de datos y realizamos el preprocesamiento necesario.

```{r pressure, echo=FALSE}

# Cargamos los datos
#fumadores = read.csv("data/smoking_driking_dataset_Ver01.csv", header = TRUE, sep = ",")
fumadores_50 <- read.csv("data/reducido.csv", header = TRUE, sep = ",")

# Verificar el número de observaciones y predictores
#num_observaciones <- nrow(fumadores)
#num_predictores <- ncol(fumadores)

num_observaciones <- nrow(fumadores_50)
num_predictores <- ncol(fumadores_50)

cat("Número de observaciones:", num_observaciones, "\n")
cat("Número de predictores:", num_predictores, "\n")
```

```{r pressure, echo=FALSE}
# Achicamos la informacion en terminos de observaciones
set.seed(44512364)
# fumadores_50 <- fumadores[sample(nrow(fumadores), 50000), ]
# write.csv(fumadores_50, "data/reducido.csv", row.names = FALSE)

# Modificamos las variables categoricas de numeros a palabras:

# Modificar la variable 'hear_left'
fumadores_50$hear_left <- factor(fumadores_50$hear_left,
                                 levels = c(1.0, 2.0),
                                 labels = c("normal", "abnormal"))

# Modificar la variable 'hear_right'
fumadores_50$hear_right <- factor(fumadores_50$hear_right,
                                  levels = c(1.0, 2.0),
                                  labels = c("normal", "abnormal"))

# Modificar la variable 'SMK_stat_type_cd'
fumadores_50$SMK_stat_type_cd <- factor(fumadores_50$SMK_stat_type_cd,
                                        levels = c(1.0, 2.0, 3.0),
                                        labels = c("never", "used to smoke but quit", "still smoke"))

# Modificar la variable 'urine_protein'
fumadores_50$urine_protein <- factor(fumadores_50$urine_protein,
                                     levels = c(1, 2, 3, 4, 5, 6),
                                     labels = c("Negativo (-)", "Trazas (+/-)", "Bajo (+1)", 
                                                "Moderado (+2)", "Alto (+3)", "Muy alto (+4)"))

# Modificar la variable 'DRK_YN'
fumadores_50$DRK_YN <- as.factor(fumadores_50$DRK_YN)

```

## Análisis exploratorio de datos

### Estadísticas descriptivas de las variables principales.

```{r pressure, echo=FALSE}
# Definir el vector con los nombres de las variables principales
variables <- c("age", "gamma_GTP", "HDL_chole", "waistline", "SBP", "LDL_chole", "triglyceride", "hemoglobin", "SGOT_AST", "SGOT_ALT", "BLDS")

# Seleccionar las variables principales
variables_principales <- fumadores_50[, variables]

# Mostrar la estructura de las variables seleccionadas
str(variables_principales)
```

### Visualizaciones relevantes

Realizamos un análisis inical de las variables con las cuales contamos e identificamos que cuando se evalúa el consumo de alcohol y se determina si una persona es alcohólica, ciertas variables clínicas juegan un papel crucial en la identificación de patrones y efectos asociados con el alcohol. Entre estas variables, Gamma-GTP, SGOT/AST y Triglicéridos se destacan como los indicadores más relevantes. Es por eso que decidimos realizar nuestras visualizaciones eb base a ellas para obtener un mejor entendimiento de estas variables.

##Box plot para Gamma-GTP según el consumo de alcohol

```{r}
# Crear el scatter plot para Gamma-GTP con línea de regresión
ggplot(fumadores_50, aes(x = as.factor(DRK_YN), y = gamma_GTP, fill = as.factor(DRK_YN))) +
  geom_boxplot(alpha = 0.5) +
  geom_smooth(method = "lm", aes(group = 1, color = "Trend"), se = FALSE) +  # Línea de regresión
  ylim(0, 50) +  # Ajustar el eje y
  labs(
    title = "Gamma-GTP según Consumo de Alcohol",
    x = "Consumo de Alcohol (0 = No, 1 = Sí)",
    y = "Gamma-GTP"
  ) +
  scale_fill_manual(values = c("light blue", "blue")) +  
  scale_color_manual(name = "Trend", values = c("blue")) +  
  theme_minimal() +
  theme(legend.position = "none")
```

##Box plot para SGOT/AST según el consumo de alcohol

```{r}
ggplot(fumadores_50, aes(x = as.factor(DRK_YN), y = SGOT_AST, fill = as.factor(DRK_YN))) +
  geom_boxplot(alpha = 0.5) +
  geom_smooth(method = "lm", aes(group = 1, color = "Trend"), se = FALSE) +  # Línea de regresión
  ylim(0, 50) +  # Ajustar el eje y
  labs(
    title = "SGOT/AST según Consumo de Alcohol",
    x = "Consumo de Alcohol (0 = No, 1 = Sí)",
    y = "SGOT/AST"
  ) +
  scale_fill_manual(values = c("light blue", "blue")) +  # Colores personalizados
  scale_color_manual(name = "Trend", values = c("blue")) +  # Color para la línea de tendencia
  theme_minimal() +
  theme(legend.position = "none")
```

### Box plot para Triglicéridos según el consumo de alcohol

```{r}
ggplot(fumadores_50, aes(x = as.factor(DRK_YN), y = triglyceride, fill = as.factor(DRK_YN))) +
  geom_boxplot(alpha = 0.5) +
  geom_smooth(method = "lm", aes(group = 1, color = "Trend"), se = FALSE) +  # Línea de regresión
  ylim(0, 50) +  # Ajustar el eje y
  labs(
    title = "Triglicéridos según Consumo de Alcohol",
    x = "Consumo de Alcohol (0 = No, 1 = Sí)",
    y = "Triglicéridos"
  ) +
  scale_fill_manual(values = c("light blue", "blue")) +  # Colores personalizados
  scale_color_manual(name = "Trend", values = c("blue")) +  # Color para la línea de tendencia
  theme_minimal() +
  theme(legend.position = "none")
```

En el análisis, se observa que las dos primeras variables presentan una relación significativa con la variable categórica. Entre ellas, Gamma-GTP muestra una correlación más fuerte en comparación con SGOT/AST. En contraste, el último gráfico revela que los niveles de triglicéridos son similares tanto en personas que consumen alcohol como en aquellas que no lo hacen. Esto sugiere que, a diferencia de Gamma-GTP y SGOT/AST, los triglicéridos no parecen estar tan relacionados con el consumo de alcohol en nuestra muestra.

### Características observadas en los datos

# 3. Construcción de un árbol de decisión básico

```{r pressure, echo=FALSE}

# Guardamos el número total de observaciones en el conjunto de datos
n <- nrow(fumadores_50)

# Definimos el tamaño de los conjuntos de entrenamiento, validación y testeo
n_train <- floor(0.70 * n)    # Asigno el 70% de las observaciones para entrenamiento
n_val <- floor(0.15 * n)      # Asigno el 15% de las observaciones para validación
n_test <- n - n_train - n_val # Asigno el resto para testeo.

# Creamos una secuencia de índices aleatorios para dividir los datos
indices <- sample(1:n)

# Dividimos los índices en los tres conjuntos
train_indices <- indices[1:n_train]
val_indices <- indices[(n_train + 1):(n_train + n_val)]
test_indices <- indices[(n_train + n_val + 1):n]

train_data <- fumadores_50[train_indices, ]
val_data <- fumadores_50[val_indices, ]
test_data <- fumadores_50[test_indices, ]

# Arbol
# Defino los parámetros de control para el modelo de árbol de decisión
control_params <- rpart.control(
  minsplit = 20,             # Número mínimo de observaciones necesarias para dividir un nodo
  minbucket = round(20/3),   # Número mínimo de observaciones en una hoja
  cp = 0.001,                # Parámetro de complejidad para evitar el sobreajuste
  xval = 10,                 # Número de particiones en la validación cruzada
  maxdepth = 30              # Profundidad máxima del árbol
)

# Creamos el modelo de árbol de decisión usando el conjunto de entrenamiento
arbol_1 <- rpart(formula = DRK_YN ~ gamma_GTP + SGOT_AST + SGOT_ALT + BLDS + HDL_chole + LDL_chole + triglyceride + age + hemoglobin,
               data = train_data, method = "class", control = control_params)

# Visualización del arbol
rpart.plot(arbol_1)
```

## Interpretación del arbol obtenido

-   Podemos visualizar que Los niveles de gamma-GTP son un factor determinante en la predicción, ya que es un marcador hepático que puede estar elevado en personas que consumen alcohol. Si la hemoglobina es mayor o igual a 14, y gamma-GTP es elevado, la probabilidad de consumo de alcohol aumenta significativamente (P = 0.78). Este es el caso donde la probabilidad de ser una persona que consume alcohol es más alta. Otros factores como la edad, el colesterol LDL, y las enzimas hepáticas SGOT_ALT y HDL también influyen en la probabilidad de consumo. El árbol muestra cómo estas variables se combinan para segmentar a las personas y estimar su comportamiento en relación con el consumo de alcohol.

# 4. Evaluacion del árbol de decision básico

## Predicciones

```{r pressure, echo=FALSE}

# Predecir las probabilidades
pred_prob <- predict(arbol_1, newdata = test_data, type = "prob")

# Predecir las clases
pred_class <- predict(arbol_1, newdata = test_data, type = "class")

head(pred_prob)
head(pred_class)
```

Los resultados presentados muestran las predicciones del modelo de árbol de decisión en términos de probabilidades y clases para un conjunto de datos de prueba.Cada fila muestra la probabilidad de que un individuo no consuma alcohol (N) o consuma alcohol (Y). Por ejemplo, el primer individuo tiene una probabilidad de 0.679 de consumir alcohol y 0.320 de no consumir. Basado en las probabilidades, el modelo asigna una clase a cada individuo. Si la probabilidad de "Y" (consumo de alcohol) es mayor que la de "N", la clase predicha es "Y", y viceversa. Utilizaremos las metricas de performance para realizar un análisis de los resultados arrojados.

## Metricas de performance

### Matriz de confusion

```{r pressure, echo=FALSE}

# Calcular la matriz de confusión
matriz_confusion <- table(Predicted = pred_class, Actual = test_data$DRK_YN)

# Convertir la matriz de confusión a un data frame en formato largo
matriz_confusion_df <- as.data.frame(melt(matriz_confusion))

# Crear el gráfico de la matriz de confusión
ggplot(matriz_confusion_df, aes(x = Actual, y = Predicted, fill = value)) +
  geom_tile(color = "blue") +
  geom_text(aes(label = value), vjust = 1) +
  scale_fill_gradient(low = "white", high = "light blue") +
  labs(title = "Matriz de Confusión",
       x = "Clase Actual",
       y = "Clase Predicha",
       fill = "Frecuencia") +
  theme_minimal()
```

La matriz de confusión muestra el rendimiento del modelo de clasificación al predecir si las personas consumen alcohol o no. Aquí está el análisis de la matriz:

-   **Verdaderos Positivos (Y-Y):** El modelo identificó correctamente a 2663 personas que consumen alcohol.

-   **Verdaderos Negativos (N-N)**: El modelo identificó correctamente a 2512 personas que no consumen alcohol.

-   **Falsos Positivos (N-Y):** 1094 personas fueron incorrectamente clasificadas como consumidoras de alcohol cuando en realidad no lo son.

-   **Falsos Negativos (Y-N)**: personas que consumen alcohol fueron incorrectamente clasificadas como no consumidoras.

### Accuracy

```{r pressure, echo=FALSE}
accuracy <- sum(diag(matriz_confusion)) / sum(matriz_confusion)
cat("Accuracy: ", accuracy, "\n")
```

-   Esta metrica hace referencia a la precisión del modelo. Mide la fracción de predicciones correctas realizadas por el modelo sobre el total de predicciones. Nos proporciona una visión general de cuán bien está funcionando el modelo en términos de predicciones correctas variando entre 0 y 1. **El accuracy de nuestro modelo es 0.69**

### Precision y Recall

```{r pressure, echo=FALSE}
precision <- matriz_confusion["Y", "Y"] / (matriz_confusion["Y", "Y"] + matriz_confusion["Y", "N"])

recall <- matriz_confusion["Y", "Y"] / (matriz_confusion["Y", "Y"] + matriz_confusion["N", "Y"])

cat("Precision: ", precision, "\n")
cat("Recall: ", recall, "\n")
```

-   El modelo tiene una precisión del 0.6838726, lo que indica que de todas las veces que el modelo predijo que una observación era positiva, aproximadamente el **68.39%** de esas predicciones eran correctas.

-   El modelo tiene un recall del 0.7088102, lo que significa que de todas las observación que realmente son positivas, el modelo identificó correctamente aproximadamente el **70.88%** de ellas.

### F1-Score

```{r pressure, echo=FALSE}
f1_score <- 2 * ((precision * recall) / (precision + recall))

cat("F1-Score: ", f1_score, "\n")

```

-   El F1-score es una métrica que combina la precisión (precision) y la recuperación (recall) en una sola medida, proporcionando una manera de evaluar el equilibrio entre estos dos aspectos en un modelo de clasificación. Un F1-score de 0.696 indica que el modelo tiene un rendimiento moderado en términos de precisión y recuperación. lo que es coherente con el inciso de Recall y precision.

```{r}
# Crear un data frame con las métricas
metrics_df <- data.frame(
  Metric = c("Accuracy", "Precision", "Recall", "F1-Score"),
  Value = c(0.69, 0.6838726, 0.7088102, 0.6961182)
)

# Crear el gráfico de barras con etiquetas de porcentaje y una escala de colores
ggplot(metrics_df, aes(x = Metric, y = Value, fill = Value)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = scales::percent(Value)), vjust = -0.3, size = 4) +  # Etiquetas en las barras
  ylim(0, 1) +  # Ajustar el eje y para que vaya de 0 a 1
  labs(title = "Métricas del Modelo de Clasificación",
       x = "Métrica",
       y = "Valor") +
  scale_fill_gradient(low = "blue", high = "lightblue") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

El F1-score de 0.696 y la accuracy de 0.69 muestran que el modelo tiene un desempeño moderado, con un buen equilibrio entre precisión y recuperación Igualmente deja un margén para la mejora del modelo dado la cantidad de flasos positivos y falsos negativos.

### AUC-ROC

```{r pressure, echo=FALSE}
roc_curve <- roc(test_data$DRK_YN, pred_prob[, "Y"], levels = rev(levels(test_data$DRK_YN)))

plot(roc_curve, col = "blue", main = "ROC Curve")

# Calcular el valor AUC
auc_value <- auc(roc_curve)
cat("AUC-ROC: ", auc_value, "\n")

print(auc_value)

```
La curva ROC es una representación gráfica que muestra el rendimiento del modelo de clasificación binaria a través de todos los posibles umbrales de decisión. En el eje Y se encuentra la sensibilidad (tasa de verdaderos positivos), que mide la proporción de casos positivos correctamente identificados por el modelo. En el eje X se encuentra la tasa de falsos positivos, que mide la proporción de casos negativos que fueron incorrectamente clasificados como positivos. En este gráfico, la curva se acerca al borde superior izquierdo, lo que indica un buen rendimiento del modelo. Sin embargo, la curva no está completamente cerca del borde lo que sugiere que hay margen de mejora.
El AUC-ROC es un valor numérico que mide el área bajo la curva ROC. Este valor varía entre 0.5 y 1.0. Con un valor de **0.7318**, el modelo tiene una capacidad razonable para distinguir entre las personas que consumen alcohol y las que no. Un AUC en este rango (0.7-0.8) generalmente indica que el modelo tiene un rendimiento aceptable, pero aún hay margen de mejora (Esto es coherente con el grafico obtenido)

## Interpretamos los resultados obtenidos

El árbol de decisión proporciona un rendimiento aceptable, pero con áreas de mejora. El AUC-ROC de 0.7318 sugiere que el modelo tiene un poder de discriminación razonable, pero la matriz de confusión y las métricas de precisión, recall y F1-score muestran que el modelo esta trabajando con una cantidad notable de errores en la clasificación. Probaremos en los proximos puntos, ajustando los hiperparametros si obtenemos una mejora del modelo en cuestión.

# 5. Optimización del modelo

## Experimentamos con diferentes valores de hiperparámetros

En este experimento, hemos llevado a cabo un proceso de optimización del árbol de decisión utilizando la métrica de rendimiento AUC-ROC como criterio principal. El objetivo era identificar la combinación óptima de hiperparámetros (maxdepth, minsplit, minbucket) que maximiza el rendimiento del modelo en el conjunto de validación.

```{r pressure, echo=FALSE}
library(rpart)
library(pROC)
library(caret)

# Definir la función para optimizar el árbol de decisión
optimize_decision_tree <- function(train_data, val_data, formula, maxdepth_values, minsplit_values, minbucket_values) {
  
  #número total de combinaciones de hiperparámetros
  total_combinations <- length(maxdepth_values) * length(minsplit_values) * length(minbucket_values)
  
  #barra de progreso para visualizar el avance del proceso
  pb <- txtProgressBar(min = 0, max = total_combinations, style = 3)
  
  # Inicializar un contador de progreso
  progress_counter <- 0
  
  #data frame vacío para almacenar los resultados
  results <- data.frame(maxdepth = integer(), minsplit = integer(), minbucket = integer(), AUC = numeric())
  
  #Vamos a probar todas las combinaciones de hiperparámetros
  for (maxdepth in maxdepth_values) {
    for (minsplit in minsplit_values) {
      for (minbucket in minbucket_values) {
        
        progress_counter <- progress_counter + 1
        setTxtProgressBar(pb, progress_counter)
        
        #Parámetros de control del árbol de decisión
        control_params <- rpart.control(minsplit = minsplit, minbucket = minbucket, cp = 0, cval = 0, maxdepth = maxdepth)
        
        #Entrenamos el árbol de decisión con los parámetros actuales
        arbol <- rpart(formula, data = train_data, method = "class", control = control_params)
        
        #Predecimos las probabilidades en el conjunto de validación
        pred_prob_val <- tryCatch({
          predict(arbol, newdata = val_data, type = "prob")
        }, error = function(e) {
          NULL
        })
        
        if (!is.null(pred_prob_val)) { # Verifica si la predicción no es NULL
          
          valid_indices <- !is.na(pred_prob_val[, "Y"]) & !is.nan(pred_prob_val[, "Y"]) & !is.na(val_data$DRK_YN) & !is.nan(val_data$DRK_YN)
          
          # Identificar índices válidos (sin NA o NaN) en las predicciones y en la variable objetivo
          if (sum(valid_indices) > 0) {
            pred_prob_val_clean <- pred_prob_val[valid_indices, ]
            val_data_clean <- val_data[valid_indices, ]
            
            roc_curve <- tryCatch({
              suppressMessages(roc(val_data_clean$DRK_YN, pred_prob_val_clean[, "Y"]))
            }, error = function(e) {
              NULL
            })
            
            if (!is.null(roc_curve)) {
              auc_value <- auc(roc_curve)
              
              results <- rbind(results, data.frame(maxdepth = maxdepth, minsplit = minsplit, minbucket = minbucket, AUC = auc_value))
            }
          }
        }
      }
    }
  }
  
  close(pb)
  
  results <- results[!is.na(results$AUC) & !is.nan(results$AUC), ]
  results$AUC <- as.numeric(as.character(results$AUC))
  
  max_auc <- max(results$AUC)
  
  best_rows <- results[results$AUC == max_auc, ]
  
  return(best_rows)
}

# Ejemplo de uso de la función
best_hyperparameters <- optimize_decision_tree(
  train_data = train_data, 
  val_data = val_data, 
  formula = DRK_YN ~ gamma_GTP + SGOT_AST + SGOT_ALT + BLDS + HDL_chole + LDL_chole + triglyceride + age + hemoglobin,
  maxdepth_values = c(5, 10, 15, 20, 25, 30),
  minsplit_values = c(2, 5, 10, 15, 20),
  minbucket_values = c(1, 3, 5, 7, 10, 15)
)

print(best_hyperparameters)

```

## Visualizaciones

```{r pressure, echo=FALSE}
# Scatter plot para maxdepth vs AUC
ggplot(results, aes(x = maxdepth, y = AUC)) +
  geom_point() +
  geom_smooth(method = "loess", se = FALSE) + 
  labs(title = "Relación entre MaxDepth y AUC", x = "MaxDepth", y = "AUC") +
  theme_minimal()

# Scatter plot para minsplit vs AUC
ggplot(results, aes(x = minsplit, y = AUC)) +
  geom_point() +
  geom_smooth(method = "loess", se = FALSE) + 
  labs(title = "Relación entre MinSplit y AUC", x = "MinSplit", y = "AUC") +
  theme_minimal()

# Scatter plot para minbucket vs AUC
ggplot(results, aes(x = minbucket, y = AUC)) +
  geom_point() +
  geom_smooth(method = "loess", se = FALSE) + 
  labs(title = "Relación entre MinBucket y AUC", x = "MinBucket", y = "AUC") +
  theme_minimal()
```

## AUC-ROC en el conjunto de testeo

```{r pressure, echo=FALSE}
best_combination <- best_hyperparameters[1, ]

best_tree <- rpart(DRK_YN ~ gamma_GTP + SGOT_AST + SGOT_ALT + BLDS + HDL_chole + LDL_chole + triglyceride + age + hemoglobin,
                   data = train_data, method = "class",
                   control = rpart.control(minsplit = best_combination$minsplit,
                                           minbucket = best_combination$minbucket,
                                           maxdepth = best_combination$maxdepth, 
                                           cp = 0,
                                           cval = 0))

pred_prob_test <- predict(best_tree, newdata = test_data, type = "prob")

valid_indices_test <- !is.na(pred_prob_test[, "Y"]) & !is.nan(pred_prob_test[, "Y"]) & !is.na(test_data$DRK_YN) & !is.nan(test_data$DRK_YN)

# Calcular el AUC-ROC en el conjunto de testeo
if (sum(valid_indices_test) > 0) {
  pred_prob_test_clean <- pred_prob_test[valid_indices_test, ]
  test_data_clean <- test_data[valid_indices_test, ]
  
  roc_curve_test <- suppressMessages(roc(test_data_clean$DRK_YN, pred_prob_test_clean[, "Y"]))
  auc_test <- auc(roc_curve_test)
  
  # Mostrar el valor de AUC-ROC en el conjunto de testeo
  cat("AUC-ROC test:", auc_test, "\n")
} else {
  cat("No hay suficientes datos válidos para calcular el AUC-ROC en el conjunto de testeo.\n")
}
```

## Comparación

```{r pressure, echo=FALSE}

# Calcular el AUC-ROC para el árbol básico
pred_prob_test_1 <- predict(arbol_1, newdata = test_data, type = "prob")

# Filtrar filas válidas (sin NA o NaN)
valid_indices_test_1 <- !is.na(pred_prob_test_1[, "Y"]) & !is.nan(pred_prob_test_1[, "Y"]) & !is.na(test_data$DRK_YN) & !is.nan(test_data$DRK_YN)

if (sum(valid_indices_test_1) > 0) {
  pred_prob_test_clean_1 <- pred_prob_test_1[valid_indices_test_1, ]
  test_data_clean_1 <- test_data[valid_indices_test_1, ]
  
  roc_curve_test_1 <- suppressMessages(roc(test_data_clean_1$DRK_YN, pred_prob_test_clean_1[, "Y"]))
  auc_test_1 <- auc(roc_curve_test_1)
  
  cat("AUC-ROC en el conjunto de testeo (árbol básico):", auc_test_1, "\n")
  } else {
  cat("No hay suficientes datos válidos para calcular el AUC-ROC en el conjunto de testeo (árbol básico).\n")
  }

cat("AUC-ROC en el conjunto de testeo (árbol optimizado):", auc_test, "\n")


```

```{r pressure, echo=FALSE}
# Función para calcular métricas adicionales
calculate_metrics <- function(actual, predicted_probs, threshold = 0.5) {
  predicted_classes <- ifelse(predicted_probs[, "Y"] >= threshold, "Y", "N")
  
  # Calcular matriz de confusión
  confusion_matrix <- confusionMatrix(as.factor(predicted_classes), as.factor(actual))
  
  # Extraer métricas
  accuracy <- confusion_matrix$overall["Accuracy"]
  precision <- confusion_matrix$byClass["Pos Pred Value"]
  recall <- confusion_matrix$byClass["Sensitivity"]
  f1_score <- confusion_matrix$byClass["F1"]
  
  return(list(accuracy = accuracy, precision = precision, recall = recall, f1_score = f1_score, confusion_matrix = confusion_matrix))
}

# Calcular el AUC-ROC y otras métricas para el árbol básico
pred_prob_test_1 <- predict(arbol_1, newdata = test_data, type = "prob")

# Filtrar filas válidas (sin NA o NaN)
valid_indices_test_1 <- !is.na(pred_prob_test_1[, "Y"]) & !is.nan(pred_prob_test_1[, "Y"]) & !is.na(test_data$DRK_YN) & !is.nan(test_data$DRK_YN)

if (sum(valid_indices_test_1) > 0) {
  pred_prob_test_clean_1 <- pred_prob_test_1[valid_indices_test_1, ]
  test_data_clean_1 <- test_data[valid_indices_test_1, ]
  
  # Calcular AUC-ROC
  roc_curve_test_1 <- suppressMessages(roc(test_data_clean_1$DRK_YN, pred_prob_test_clean_1[, "Y"]))
  auc_test_1 <- auc(roc_curve_test_1)
  cat("AUC-ROC en el conjunto de testeo (árbol básico):", auc_test_1, "\n")
  
  # Calcular métricas adicionales
  metrics_basic <- calculate_metrics(test_data_clean_1$DRK_YN, pred_prob_test_clean_1)
  cat("Precisión (árbol básico):", metrics_basic$accuracy, "\n")
  cat("Recall (árbol básico):", metrics_basic$recall, "\n")
  cat("F1-Score (árbol básico):", metrics_basic$f1_score, "\n")
  cat("Matriz de confusión (árbol básico):\n")
  print(metrics_basic$confusion_matrix$table)
  
} else {
  cat("No hay suficientes datos válidos para calcular el AUC-ROC en el conjunto de testeo (árbol básico).\n")
}

# Calcular AUC-ROC y otras métricas para el árbol optimizado
if (sum(valid_indices_test) > 0) {
  pred_prob_test_clean <- pred_prob_test[valid_indices_test, ]
  test_data_clean <- test_data[valid_indices_test, ]
  
  # Calcular AUC-ROC
  roc_curve_test_opt <- suppressMessages(roc(test_data_clean$DRK_YN, pred_prob_test_clean[, "Y"]))
  auc_test_opt <- auc(roc_curve_test_opt)
  cat("AUC-ROC en el conjunto de testeo (árbol optimizado):", auc_test_opt, "\n")
  
  # Calcular métricas adicionales
  metrics_opt <- calculate_metrics(test_data_clean$DRK_YN, pred_prob_test_clean)
  cat("Precisión (árbol optimizado):", metrics_opt$accuracy, "\n")
  cat("Recall (árbol optimizado):", metrics_opt$recall, "\n")
  cat("F1-Score (árbol optimizado):", metrics_opt$f1_score, "\n")
  cat("Matriz de confusión (árbol optimizado):\n")
  print(metrics_opt$confusion_matrix$table)
  
} else {
  cat("No hay suficientes datos válidos para calcular el AUC-ROC en el conjunto de testeo (árbol optimizado).\n")
}
```

# 6. Interpretación de resultados

## Comparar Visualmente los Árboles

```{r pressure, echo=FALSE}
# Graficar el árbol básico
rpart.plot(arbol_1, main = "Árbol Básico")

# Graficar el árbol optimizado
rpart.plot(best_tree, main = "Árbol Optimizado")
```

(ESCRIBIR)

## Importancia de las variables

```{r pressure, echo=FALSE}
# Importancia de las variables para el árbol básico
importance_basic <- varImp(arbol_1)
cat("Importancia de las variables en el Árbol Básico:\n")
print(importance_basic)

# Importancia de las variables para el árbol optimizado
importance_opt <- varImp(best_tree)
cat("Importancia de las variables en el Árbol Optimizado:\n")
print(importance_opt)
```

## Visualización de la Importancia de las Variables

```{r pressure, echo=FALSE}
# Convertir la importancia a un dataframe para graficar
importance_basic_df <- data.frame(Variable = rownames(importance_basic), Importance = importance_basic[,1])
importance_opt_df <- data.frame(Variable = rownames(importance_opt), Importance = importance_opt[,1])

# Graficar la importancia de las variables - Árbol Básico
ggplot(importance_basic_df, aes(x = reorder(Variable, Importance), y = Importance)) +
  geom_bar(stat = "identity", fill = "blue") +
  coord_flip() +
  labs(title = "Importancia de las Variables - Árbol Básico", x = "Variable", y = "Importancia") +
  theme_minimal()

# Graficar la importancia de las variables - Árbol Optimizado
ggplot(importance_opt_df, aes(x = reorder(Variable, Importance), y = Importance)) +
  geom_bar(stat = "identity", fill = "red") +
  coord_flip() +
  labs(title = "Importancia de las Variables - Árbol Optimizado", x = "Variable", y = "Importancia") +
  theme_minimal()

```

(ESCRIBIR)

# 7. Análisis del impacto de los valores faltantes

## Generamos tres nuevos sets de conjuntos de datos

```{r pressure, echo=FALSE}
replace_with_na <- function(df, prob) {
  df_na <- df
  n_values <- nrow(df_na) * ncol(df_na)
  n_na <- floor(prob * n_values)
  
  # Obtener una muestra de posiciones para reemplazar con NA
  na_indices <- sample(seq_len(n_values), size = n_na)
  
  # Convertir el índice lineal en índices de fila y columna
  row_indices <- ((na_indices - 1) %% nrow(df_na)) + 1
  col_indices <- ((na_indices - 1) %/% nrow(df_na)) + 1
  
  # Reemplazar con NA
  for (i in seq_along(na_indices)) {
    df_na[row_indices[i], col_indices[i]] <- NA
  }
  
  return(df_na)
}
```

```{r pressure, echo=FALSE}
# Generar el primer set con 20% de NAs
train_data_20 <- replace_with_na(train_data, 0.20)
val_data_20 <- replace_with_na(val_data, 0.20)
test_data_20 <- replace_with_na(test_data, 0.20)

# Generar el segundo set con 50% de NAs
train_data_50 <- replace_with_na(train_data, 0.50)
val_data_50 <- replace_with_na(val_data, 0.50)
test_data_50 <- replace_with_na(test_data, 0.50)

# Generar el tercer set con 75% de NAs
train_data_75 <- replace_with_na(train_data, 0.75)
val_data_75 <- replace_with_na(val_data, 0.75)
test_data_75 <- replace_with_na(test_data, 0.75)

```

```{r pressure, echo=FALSE}
cat("Proporción de NAs en el conjunto de entrenamiento con 20% de reemplazo:", mean(is.na(train_data_20)), "\n")
cat("Proporción de NAs en el conjunto de validación con 50% de reemplazo:", mean(is.na(val_data_50)), "\n")
cat("Proporción de NAs en el conjunto de testeo con 75% de reemplazo:", mean(is.na(test_data_75)), "\n")
```

## Árbol para el set de 20% de NAs

```{r pressure, echo=FALSE}
best_hyperparameters_20 <- optimize_decision_tree(
  train_data = train_data_20, 
  val_data = val_data_20, 
  formula = DRK_YN ~ gamma_GTP + SGOT_AST + SGOT_ALT + BLDS + HDL_chole + LDL_chole + triglyceride + age + hemoglobin,
  maxdepth_values = c(5, 10, 15, 20, 25, 30),
  minsplit_values = c(2, 5, 10, 15, 20),
  minbucket_values = c(1, 3, 5, 7, 10, 15)
)

best_combination_20 <- best_hyperparameters_20[1, ]

best_tree_20 <- rpart(DRK_YN ~ gamma_GTP + SGOT_AST + SGOT_ALT + BLDS + HDL_chole + LDL_chole + triglyceride + age + hemoglobin,
                   data = train_data_20, method = "class",
                   control = rpart.control(minsplit = best_combination_20$minsplit,
                                           minbucket = best_combination_20$minbucket,
                                           maxdepth = best_combination_20$maxdepth, 
                                           cp = 0,
                                           cval = 0))

pred_prob_test_20 <- predict(best_tree_20, newdata = test_data_20, type = "prob")

valid_indices_test_20 <- !is.na(pred_prob_test_20[, "Y"]) & !is.nan(pred_prob_test_20[, "Y"]) & !is.na(test_data_20$DRK_YN) & !is.nan(test_data_20$DRK_YN)

# Calcular el AUC-ROC en el conjunto de testeo
if (sum(valid_indices_test_20) > 0) {
  pred_prob_test_clean_20 <- pred_prob_test_20[valid_indices_test_20, ]
  test_data_clean_20 <- test_data_20[valid_indices_test_20, ]
  
  roc_curve_test_20 <- suppressMessages(roc(test_data_clean_20$DRK_YN, pred_prob_test_clean_20[, "Y"]))
  auc_test_20 <- auc(roc_curve_test_20)
  
  # Mostrar el valor de AUC-ROC en el conjunto de testeo
  cat("AUC-ROC test:", auc_test_20, "\n")
} else {
  cat("No hay suficientes datos válidos para calcular el AUC-ROC en el conjunto de testeo.\n")
}

```

## Árbol para el set de 50% de NAs

```{r pressure, echo=FALSE}
best_hyperparameters_50 <- optimize_decision_tree(
  train_data = train_data_50, 
  val_data = val_data_50, 
  formula = DRK_YN ~ gamma_GTP + SGOT_AST + SGOT_ALT + BLDS + HDL_chole + LDL_chole + triglyceride + age + hemoglobin,
  maxdepth_values = c(5, 10, 15, 20, 25, 30),
  minsplit_values = c(2, 5, 10, 15, 20),
  minbucket_values = c(1, 3, 5, 7, 10, 15)
)

best_combination_50 <- best_hyperparameters_50[1, ]

best_tree_50 <- rpart(DRK_YN ~ gamma_GTP + SGOT_AST + SGOT_ALT + BLDS + HDL_chole + LDL_chole + triglyceride + age + hemoglobin,
                   data = train_data_50, method = "class",
                   control = rpart.control(minsplit = best_combination_50$minsplit,
                                           minbucket = best_combination_50$minbucket,
                                           maxdepth = best_combination_50$maxdepth, 
                                           cp = 0))

pred_prob_test_50 <- predict(best_tree_50, newdata = test_data_50, type = "prob")

valid_indices_test_50 <- !is.na(pred_prob_test_50[, "Y"]) & !is.nan(pred_prob_test_50[, "Y"]) & !is.na(test_data_50$DRK_YN) & !is.nan(test_data_50$DRK_YN)

# Calcular el AUC-ROC en el conjunto de testeo
if (sum(valid_indices_test_50) > 0) {
  pred_prob_test_clean_50 <- pred_prob_test_50[valid_indices_test_50, ]
  test_data_clean_50 <- test_data_50[valid_indices_test_50, ]
  
  roc_curve_test_50 <- suppressMessages(roc(test_data_clean_50$DRK_YN, pred_prob_test_clean_50[, "Y"]))
  auc_test_50 <- auc(roc_curve_test_50)
  
  # Mostrar el valor de AUC-ROC en el conjunto de testeo
  cat("AUC-ROC en el conjunto de testeo (50% NAs):", auc_test_50, "\n")
} else {
  cat("No hay suficientes datos válidos para calcular el AUC-ROC en el conjunto de testeo (50% NAs).\n")
}

```

## Árbol para el set de 75% de NAs

```{r pressure, echo=FALSE}
best_hyperparameters_75 <- optimize_decision_tree(
  train_data = train_data_75, 
  val_data = val_data_75, 
  formula = DRK_YN ~ gamma_GTP + SGOT_AST + SGOT_ALT + BLDS + HDL_chole + LDL_chole + triglyceride + age + hemoglobin,
  maxdepth_values = c(5, 10, 15, 20, 25, 30),
  minsplit_values = c(2, 5, 10, 15, 20),
  minbucket_values = c(1, 3, 5, 7, 10, 15)
)

best_combination_75 <- best_hyperparameters_75[1, ]

best_tree_75 <- rpart(DRK_YN ~ gamma_GTP + SGOT_AST + SGOT_ALT + BLDS + HDL_chole + LDL_chole + triglyceride + age + hemoglobin,
                   data = train_data_75, method = "class",
                   control = rpart.control(minsplit = best_combination_75$minsplit,
                                           minbucket = best_combination_75$minbucket,
                                           maxdepth = best_combination_75$maxdepth, 
                                           cp = 0))

pred_prob_test_75 <- predict(best_tree_75, newdata = test_data_75, type = "prob")

valid_indices_test_75 <- !is.na(pred_prob_test_75[, "Y"]) & !is.nan(pred_prob_test_75[, "Y"]) & !is.na(test_data_75$DRK_YN) & !is.nan(test_data_75$DRK_YN)

# Calcular el AUC-ROC en el conjunto de testeo
if (sum(valid_indices_test_75) > 0) {
  pred_prob_test_clean_75 <- pred_prob_test_75[valid_indices_test_75, ]
  test_data_clean_75 <- test_data_75[valid_indices_test_75, ]
  
  roc_curve_test_75 <- suppressMessages(roc(test_data_clean_75$DRK_YN, pred_prob_test_clean_75[, "Y"]))
  auc_test_75 <- auc(roc_curve_test_75)
  
  # Mostrar el valor de AUC-ROC en el conjunto de testeo
  cat("AUC-ROC en el conjunto de testeo (75% NAs):", auc_test_75, "\n")
} else {
  cat("No hay suficientes datos válidos para calcular el AUC-ROC en el conjunto de testeo (75% NAs).\n")
}


```

## Comparación del rendimiento en testeo del mejor árbol obtenido con la performance obtenida por el árbol optimizado del punto 5

```{r pressure, echo=FALSE}
# Función para calcular métricas adicionales
calculate_metrics <- function(actual, predicted_probs, threshold = 0.5) {
  predicted_classes <- ifelse(predicted_probs[, "Y"] >= threshold, "Y", "N")
  
  # Calcular matriz de confusión
  confusion_matrix <- confusionMatrix(as.factor(predicted_classes), as.factor(actual))
  
  # Extraer métricas
  accuracy <- confusion_matrix$overall["Accuracy"]
  precision <- confusion_matrix$byClass["Pos Pred Value"]
  recall <- confusion_matrix$byClass["Sensitivity"]
  f1_score <- confusion_matrix$byClass["F1"]
  
  return(list(accuracy = accuracy, precision = precision, recall = recall, f1_score = f1_score, confusion_matrix = confusion_matrix))
}

# Función para evaluar un árbol en el conjunto de testeo
evaluate_tree_performance <- function(best_tree, test_data, label) {
  pred_prob_test <- predict(best_tree, newdata = test_data, type = "prob")
  
  valid_indices_test <- !is.na(pred_prob_test[, "Y"]) & !is.nan(pred_prob_test[, "Y"]) & !is.na(test_data$DRK_YN) & !is.nan(test_data$DRK_YN)
  
  if (sum(valid_indices_test) > 0) {
    pred_prob_test_clean <- pred_prob_test[valid_indices_test, ]
    test_data_clean <- test_data[valid_indices_test, ]
    
    # Calcular AUC-ROC
    roc_curve_test <- suppressMessages(roc(test_data_clean$DRK_YN, pred_prob_test_clean[, "Y"]))
    auc_test <- auc(roc_curve_test)
    cat("AUC-ROC en el conjunto de testeo (", label, "):", auc_test, "\n")
    
    # Calcular métricas adicionales
    metrics <- calculate_metrics(test_data_clean$DRK_YN, pred_prob_test_clean)
    cat("Precisión (", label, "):", metrics$accuracy, "\n")
    cat("Recall (", label, "):", metrics$recall, "\n")
    cat("F1-Score (", label, "):", metrics$f1_score, "\n")
    cat("Matriz de confusión (", label, "):\n")
    print(metrics$confusion_matrix$table)
    
    return(list(auc = auc_test, metrics = metrics))
  } else {
    cat("No hay suficientes datos válidos para calcular el AUC-ROC en el conjunto de testeo (", label, ").\n")
    return(NULL)
  }
}

# Evaluar el árbol optimizado del punto 5 en el conjunto de testeo original
performance_opt <- evaluate_tree_performance(best_tree, test_data, "árbol optimizado del punto 5")

# Evaluar el mejor árbol con 20% de NAs
performance_20 <- evaluate_tree_performance(best_tree_20, test_data_20, "20% NAs")

# Evaluar el mejor árbol con 50% de NAs
performance_50 <- evaluate_tree_performance(best_tree_50, test_data_50, "50% NAs")

# Evaluar el mejor árbol con 75% de NAs
performance_75 <- evaluate_tree_performance(best_tree_75, test_data_75, "75% NAs")

# Comparación y análisis
cat("\nComparación del AUC-ROC en el conjunto de testeo:\n")
cat("AUC-ROC (árbol optimizado del punto 5):", performance_opt$auc, "\n")
cat("AUC-ROC (20% NAs):", performance_20$auc, "\n")
cat("AUC-ROC (50% NAs):", performance_50$auc, "\n")
cat("AUC-ROC (75% NAs):", performance_75$auc, "\n")

```
